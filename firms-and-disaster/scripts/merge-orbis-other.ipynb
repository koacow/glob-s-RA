{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a133ddc",
   "metadata": {},
   "source": [
    "# Merging Orbis Miscellaneous Datasets\n",
    "\n",
    "## This notebook merges the Orbis miscellaneous datasets (Industry, Legal, Location data, ownership, etc.) into a single dataset.\n",
    "\n",
    "## Technical Notes:\n",
    "\n",
    "- This notebook uses `dask` instead of `pandas` to handle large datasets that do not fit into memory. \n",
    "\n",
    "- Ownership data is merged separately to avoid memory issues, as it can be quite large.\n",
    "\n",
    "- The `orbis-info-merged.csv` file consists of the following files: \"Industries&Activities_Final_Dataset.csv\", \"legal_combined_new.csv\", \"Location_data.csv\"\n",
    " \n",
    "- The `orbis-ownership-merged.csv` file consists of the \"Ownership_combined_Part*.csv\" files.\n",
    "\n",
    "- There are issues with mixed types so read every column as a string.\n",
    "\n",
    "## How to use:\n",
    "\n",
    "- Make sure you have the required libraries installed. You can install them using pip:\n",
    "```bash\n",
    "pip install \"dask[complete]\"\n",
    "```\n",
    "\n",
    "- Change the `dataset_dir` variable to point to the directory where your Orbis datasets are stored.\n",
    "\n",
    "- Run the notebook. The merged dataset will be saved as a CSV file in the specified output directory.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08713e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95b4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.getcwd(), \"../unmerged-datasets/orbis-other\")\n",
    "out_dir = os.path.join(os.getcwd(), \"../merged-datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company name Latin alphabet', 'BvD ID number', 'Orbis ID number',\n",
      "       'Ticker symbol', 'Primary code(s) in national industry classification',\n",
      "       'US SIC, core code (3 digits)', 'BvD sectors', 'Peer Group Name',\n",
      "       'Peer Group Size', 'Main customers', 'Status', 'Status date',\n",
      "       'Status updated date', 'Date of incorporation', 'Address Line 1',\n",
      "       'Latitude', 'Longitude', 'City', 'Country ISO code', 'Full Address'],\n",
      "      dtype='object')\n",
      "Number of columns in merged info dataframe: 20\n",
      "Number of rows in merged info dataframe: 1272454\n"
     ]
    }
   ],
   "source": [
    "index_cols = [\"Orbis ID number\", \"BvD ID number\"]\n",
    "\n",
    "merged_info_df = None\n",
    "\n",
    "info_files = [\n",
    "    \"Industries&Activities_Final_Dataset.csv\",\n",
    "    \"legal_combined_new.csv\",\n",
    "    \"Location_data.csv\"\n",
    "]\n",
    "\n",
    "for filename in info_files:\n",
    "    df = dd.read_csv(os.path.join(dataset_dir, filename), dtype=str)\n",
    "    # This seems to be a redundant column that appears in some files\n",
    "    # but not others, so we drop it if it exists.\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    df[\"BvD ID number\"] = df[\"BvD ID number\"].str.upper()\n",
    "    if merged_info_df is None:\n",
    "        merged_info_df = df\n",
    "    else:\n",
    "        # Merge the new dataframe with the existing merged dataframe\n",
    "        merged_info_df = dd.merge(merged_info_df, df, on=index_cols, how='outer', suffixes=('', '_dup'))\n",
    "        dup_cols = [col for col in merged_info_df.columns if col.endswith('_dup')]\n",
    "        if dup_cols:\n",
    "            merged_info_df = merged_info_df.drop(columns=dup_cols)\n",
    "\n",
    "        # Clean up memory\n",
    "        merged_info_df = merged_info_df.repartition(partition_size=\"100MB\")\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "if merged_info_df is not None:\n",
    "    print(merged_info_df.columns)\n",
    "    print(\"Number of columns in merged info dataframe:\", len(merged_info_df.columns))\n",
    "    print(f\"Number of rows in merged info dataframe: {merged_info_df.shape[0].compute()}\")\n",
    "else:\n",
    "    print(\"No info files found in the dataset directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05566c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/koacow/repos/glob-s-RA/firms-and-disaster/merged-datasets/orbis-info-merged.csv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_info_df.to_csv(\n",
    "    os.path.join(out_dir, \"orbis-info-merged.csv\"),\n",
    "    single_file=True,\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98f295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company name Latin alphabet', 'BvD ID number', 'Orbis ID number',\n",
      "       'Ticker symbol', 'No of companies in corporate group', 'Entity type',\n",
      "       'ISH - BvD ID number', 'ISH - Orbis ID number', 'GUO - Name',\n",
      "       'GUO - BvD ID number', 'GUO - Orbis ID number', 'GUO - Ticker symbol',\n",
      "       'GUO - Country ISO code', 'GUO - City', 'GUO - Type',\n",
      "       'GUO - US SIC, Core code', 'GUO - Direct %', 'GUO - Total %',\n",
      "       'GUO - Operating revenue (Turnover)\\nm USD',\n",
      "       'GUO - Total assets\\nm USD', 'GUO - Number of employees', 'DUO - Name',\n",
      "       'DUO - BvD ID number', 'DUO - Orbis ID number',\n",
      "       'DUO - Country ISO code', 'DUO - City', 'DUO - Type',\n",
      "       'DUO - US SIC, Core code', 'DUO - Direct %', 'DUO - Total %',\n",
      "       'DUO - Operating revenue (Turnover)\\nm USD',\n",
      "       'DUO - Total assets\\nm USD', 'DUO - Number of employees',\n",
      "       'No of subsidiaries', 'Number of publications', 'HQ - HeadquartersName',\n",
      "       'HQ - HeadquartersBvD ID number', 'HQ - HeadquartersOrbis ID number',\n",
      "       'HQ - HeadquartersCity', 'HQ - HeadquartersUS SIC, Core code',\n",
      "       'HQ - HeadquartersCountry ISO code'],\n",
      "      dtype='object')\n",
      "Number of columns in merged ownership dataframe: 41\n",
      "Number of rows in merged ownership dataframe: 49573021\n"
     ]
    }
   ],
   "source": [
    "merged_ownership_df = None\n",
    "\n",
    "index_cols = [\"BvD ID number\", \"Orbis ID number\"]\n",
    "dtypes = {\n",
    "    \"Orbis ID number\": \"str\",\n",
    "    \"BvD ID number\": \"str\",\n",
    "    \"GUO - Orbis ID number\": \"str\",\n",
    "    \"GUO - BvD ID number\": \"str\",\n",
    "    \"ISH - Orbis ID number\": \"str\",\n",
    "    \"ISH - BvD ID number\": \"str\",\n",
    "    'GUO - Operating revenue (Turnover)\\nm USD': 'str',\n",
    "    'GUO - Total %': 'str',\n",
    "    'GUO - Total assets\\nm USD': 'str',\n",
    "    'GUO - Direct %': 'str',\n",
    "    'GUO - Number of employees': 'str',\n",
    "    'DUO - Total assets\\nm USD': 'str',\n",
    "    'No of subsidiaries': 'str',\n",
    "    'Number of publications': 'str',\n",
    "    'DUO - Operating revenue (Turnover)\\nm USD': 'str',\n",
    "    'DUO - Orbis ID number': 'str',\n",
    "    'DUO - Total %': 'str',\n",
    "    'DUO - Direct %': 'str',\n",
    "    'DUO - Number of employees': 'str',\n",
    "    'HQ - HeadquartersCity': 'str',\n",
    "    'HQ - HeadquartersCountry ISO code': 'str',\n",
    "    'HQ - HeadquartersName': 'str'\n",
    "}\n",
    "\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.startswith(\"Ownership_\") and filename.endswith(\".csv\"):\n",
    "        df = dd.read_csv(os.path.join(dataset_dir, filename), dtype=str)\n",
    "\n",
    "        # These seem to be redundant columns that appear in some files but not others,\n",
    "        # so we drop them if they exist.\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "        if \"Unnamed: 0.1\" in df.columns:\n",
    "            df = df.drop(\"Unnamed: 0.1\", axis=1)\n",
    "        df[\"BvD ID number\"] = df[\"BvD ID number\"].str.upper()\n",
    "        if merged_ownership_df is None:\n",
    "            merged_ownership_df = df\n",
    "        else:\n",
    "            merged_ownership_df = dd.merge(merged_ownership_df, df, on=index_cols, how='outer', suffixes=('', '_dup'))\n",
    "            # Remove duplicate columns that were created during the merge\n",
    "            dup_cols = [col for col in merged_ownership_df.columns if col.endswith('_dup')]\n",
    "            if dup_cols:\n",
    "                merged_ownership_df = merged_ownership_df.drop(columns=dup_cols)\n",
    "\n",
    "            # Clean up memory\n",
    "            merged_ownership_df = merged_ownership_df.repartition(partition_size=\"100MB\")\n",
    "            del df\n",
    "            gc.collect()\n",
    "if merged_ownership_df is not None:\n",
    "    print(merged_ownership_df.columns)\n",
    "    print(\"Number of columns in merged ownership dataframe:\", len(merged_ownership_df.columns))\n",
    "    print(f\"Number of rows in merged ownership dataframe: {merged_ownership_df.shape[0].compute()}\")\n",
    "else:\n",
    "    print(\"No ownership files found in the dataset directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9725da92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49573020"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of rows with null values in 'BvD ID number' and 'Orbis ID number'\n",
    "merged_ownership_df = merged_ownership_df.dropna(subset=index_cols, how='all')\n",
    "merged_ownership_df.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc91d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ownership_df.to_csv(\n",
    "    os.path.join(out_dir, \"orbis-ownership-merged.csv\"),\n",
    "    single_file=True,\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
